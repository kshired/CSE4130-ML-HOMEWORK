{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 기초 머신 러닝 project 3\n",
        "# 학번 : 20171612\n",
        "# 이름 : 김성일"
      ],
      "metadata": {
        "id": "OepZ94VwiKAw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q5nnj2aFcXT"
      },
      "source": [
        "# Fashion MNIST\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sTXpgKIzE0Z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6abb74c-1ab8-44b6-de89-cb3eb2d8b456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "26435584/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000, 784)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "375/375 [==============================] - 11s 27ms/step - loss: 1.0907 - accuracy: 0.6784 - val_loss: 0.7217 - val_accuracy: 0.7722\n",
            "Epoch 2/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.6525 - accuracy: 0.7917 - val_loss: 0.5989 - val_accuracy: 0.8001\n",
            "Epoch 3/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.5634 - accuracy: 0.8144 - val_loss: 0.5387 - val_accuracy: 0.8148\n",
            "Epoch 4/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.5192 - accuracy: 0.8277 - val_loss: 0.5138 - val_accuracy: 0.8227\n",
            "Epoch 5/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4924 - accuracy: 0.8334 - val_loss: 0.4835 - val_accuracy: 0.8301\n",
            "Epoch 6/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4726 - accuracy: 0.8377 - val_loss: 0.4732 - val_accuracy: 0.8323\n",
            "Epoch 7/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4585 - accuracy: 0.8423 - val_loss: 0.4587 - val_accuracy: 0.8408\n",
            "Epoch 8/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4451 - accuracy: 0.8469 - val_loss: 0.4475 - val_accuracy: 0.8422\n",
            "Epoch 9/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.4352 - accuracy: 0.8498 - val_loss: 0.4368 - val_accuracy: 0.8492\n",
            "Epoch 10/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4266 - accuracy: 0.8514 - val_loss: 0.4579 - val_accuracy: 0.8372\n",
            "Epoch 11/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.4185 - accuracy: 0.8556 - val_loss: 0.4246 - val_accuracy: 0.8496\n",
            "Epoch 12/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.4125 - accuracy: 0.8583 - val_loss: 0.4231 - val_accuracy: 0.8520\n",
            "Epoch 13/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4056 - accuracy: 0.8596 - val_loss: 0.4129 - val_accuracy: 0.8547\n",
            "Epoch 14/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3999 - accuracy: 0.8614 - val_loss: 0.4114 - val_accuracy: 0.8576\n",
            "Epoch 15/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3937 - accuracy: 0.8648 - val_loss: 0.4146 - val_accuracy: 0.8543\n",
            "Epoch 16/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3890 - accuracy: 0.8657 - val_loss: 0.4006 - val_accuracy: 0.8613\n",
            "Epoch 17/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3848 - accuracy: 0.8658 - val_loss: 0.3994 - val_accuracy: 0.8607\n",
            "Epoch 18/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3803 - accuracy: 0.8679 - val_loss: 0.3961 - val_accuracy: 0.8626\n",
            "Epoch 19/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3761 - accuracy: 0.8698 - val_loss: 0.4073 - val_accuracy: 0.8582\n",
            "Epoch 20/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3729 - accuracy: 0.8706 - val_loss: 0.3942 - val_accuracy: 0.8639\n",
            "Epoch 21/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3680 - accuracy: 0.8728 - val_loss: 0.3887 - val_accuracy: 0.8642\n",
            "Epoch 22/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3636 - accuracy: 0.8745 - val_loss: 0.3863 - val_accuracy: 0.8656\n",
            "Epoch 23/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3610 - accuracy: 0.8744 - val_loss: 0.3873 - val_accuracy: 0.8661\n",
            "Epoch 24/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3589 - accuracy: 0.8754 - val_loss: 0.3774 - val_accuracy: 0.8689\n",
            "Epoch 25/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3537 - accuracy: 0.8772 - val_loss: 0.3773 - val_accuracy: 0.8682\n",
            "Epoch 26/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3517 - accuracy: 0.8780 - val_loss: 0.3830 - val_accuracy: 0.8673\n",
            "Epoch 27/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3483 - accuracy: 0.8791 - val_loss: 0.3808 - val_accuracy: 0.8673\n",
            "Epoch 28/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3458 - accuracy: 0.8794 - val_loss: 0.3824 - val_accuracy: 0.8668\n",
            "Epoch 29/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3425 - accuracy: 0.8804 - val_loss: 0.3694 - val_accuracy: 0.8697\n",
            "Epoch 30/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3409 - accuracy: 0.8815 - val_loss: 0.3708 - val_accuracy: 0.8708\n",
            "Epoch 31/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3373 - accuracy: 0.8819 - val_loss: 0.3715 - val_accuracy: 0.8705\n",
            "Epoch 32/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3338 - accuracy: 0.8840 - val_loss: 0.3706 - val_accuracy: 0.8722\n",
            "Epoch 33/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3321 - accuracy: 0.8834 - val_loss: 0.3625 - val_accuracy: 0.8737\n",
            "Epoch 34/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3295 - accuracy: 0.8850 - val_loss: 0.3591 - val_accuracy: 0.8757\n",
            "Epoch 35/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3266 - accuracy: 0.8858 - val_loss: 0.3573 - val_accuracy: 0.8743\n",
            "Epoch 36/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3245 - accuracy: 0.8870 - val_loss: 0.3635 - val_accuracy: 0.8724\n",
            "Epoch 37/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3210 - accuracy: 0.8886 - val_loss: 0.3617 - val_accuracy: 0.8731\n",
            "Epoch 38/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3190 - accuracy: 0.8879 - val_loss: 0.3526 - val_accuracy: 0.8767\n",
            "Epoch 39/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3170 - accuracy: 0.8892 - val_loss: 0.3618 - val_accuracy: 0.8739\n",
            "Epoch 40/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3143 - accuracy: 0.8893 - val_loss: 0.3494 - val_accuracy: 0.8773\n",
            "Epoch 41/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3129 - accuracy: 0.8892 - val_loss: 0.3762 - val_accuracy: 0.8648\n",
            "Epoch 42/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3108 - accuracy: 0.8921 - val_loss: 0.3882 - val_accuracy: 0.8621\n",
            "Epoch 43/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3079 - accuracy: 0.8915 - val_loss: 0.3569 - val_accuracy: 0.8742\n",
            "Epoch 44/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3052 - accuracy: 0.8926 - val_loss: 0.3502 - val_accuracy: 0.8786\n",
            "Epoch 45/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.3040 - accuracy: 0.8931 - val_loss: 0.3493 - val_accuracy: 0.8774\n",
            "Epoch 46/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3017 - accuracy: 0.8935 - val_loss: 0.3510 - val_accuracy: 0.8767\n",
            "Epoch 47/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.2998 - accuracy: 0.8939 - val_loss: 0.3419 - val_accuracy: 0.8788\n",
            "Epoch 48/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.2974 - accuracy: 0.8956 - val_loss: 0.3460 - val_accuracy: 0.8777\n",
            "Epoch 49/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.2950 - accuracy: 0.8957 - val_loss: 0.3422 - val_accuracy: 0.8783\n",
            "Epoch 50/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.2931 - accuracy: 0.8964 - val_loss: 0.3535 - val_accuracy: 0.8726\n",
            "Epoch 51/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.2907 - accuracy: 0.8971 - val_loss: 0.3453 - val_accuracy: 0.8775\n",
            "Epoch 52/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.2886 - accuracy: 0.8991 - val_loss: 0.3392 - val_accuracy: 0.8806\n",
            "Epoch 53/60\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.2866 - accuracy: 0.8983 - val_loss: 0.3381 - val_accuracy: 0.8815\n",
            "Epoch 54/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.2858 - accuracy: 0.8986 - val_loss: 0.3416 - val_accuracy: 0.8807\n",
            "Epoch 55/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.2836 - accuracy: 0.8986 - val_loss: 0.3383 - val_accuracy: 0.8798\n",
            "Epoch 56/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.2827 - accuracy: 0.9003 - val_loss: 0.3348 - val_accuracy: 0.8813\n",
            "Epoch 57/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.2791 - accuracy: 0.9015 - val_loss: 0.3645 - val_accuracy: 0.8725\n",
            "Epoch 58/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.2785 - accuracy: 0.9015 - val_loss: 0.3334 - val_accuracy: 0.8803\n",
            "Epoch 59/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.2766 - accuracy: 0.9027 - val_loss: 0.3381 - val_accuracy: 0.8789\n",
            "Epoch 60/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.2753 - accuracy: 0.9029 - val_loss: 0.3289 - val_accuracy: 0.8830\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3504 - accuracy: 0.8732\n",
            "0.873199999332428\n",
            "Accuracy: 87.32%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os, random\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#from keras.utils import to_categorical\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "os.path.expanduser = lambda path: './'\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 60\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "print(x_train.shape)\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "print(x_train.shape)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
        "print(metrics[1])\n",
        "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1-rvZo-FWVz"
      },
      "source": [
        "# Drop Out ( 0.2 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sGZUdm2EFm6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b94998f-5d78-4ed6-e35e-8a75db3682a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 1.1965 - accuracy: 0.6196 - val_loss: 0.7337 - val_accuracy: 0.7556\n",
            "Epoch 2/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.7406 - accuracy: 0.7518 - val_loss: 0.6155 - val_accuracy: 0.7908\n",
            "Epoch 3/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6476 - accuracy: 0.7794 - val_loss: 0.5577 - val_accuracy: 0.8115\n",
            "Epoch 4/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.5926 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.8215\n",
            "Epoch 5/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5588 - accuracy: 0.8096 - val_loss: 0.5021 - val_accuracy: 0.8295\n",
            "Epoch 6/60\n",
            "375/375 [==============================] - 9s 25ms/step - loss: 0.5347 - accuracy: 0.8161 - val_loss: 0.4840 - val_accuracy: 0.8357\n",
            "Epoch 7/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5134 - accuracy: 0.8235 - val_loss: 0.4705 - val_accuracy: 0.8391\n",
            "Epoch 8/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4967 - accuracy: 0.8300 - val_loss: 0.4583 - val_accuracy: 0.8435\n",
            "Epoch 9/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4863 - accuracy: 0.8311 - val_loss: 0.4557 - val_accuracy: 0.8410\n",
            "Epoch 10/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4727 - accuracy: 0.8353 - val_loss: 0.4435 - val_accuracy: 0.8468\n",
            "Epoch 11/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4651 - accuracy: 0.8389 - val_loss: 0.4385 - val_accuracy: 0.8475\n",
            "Epoch 12/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4571 - accuracy: 0.8416 - val_loss: 0.4285 - val_accuracy: 0.8503\n",
            "Epoch 13/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4450 - accuracy: 0.8444 - val_loss: 0.4262 - val_accuracy: 0.8505\n",
            "Epoch 14/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4398 - accuracy: 0.8474 - val_loss: 0.4171 - val_accuracy: 0.8554\n",
            "Epoch 15/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4329 - accuracy: 0.8497 - val_loss: 0.4087 - val_accuracy: 0.8576\n",
            "Epoch 16/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4258 - accuracy: 0.8498 - val_loss: 0.4091 - val_accuracy: 0.8586\n",
            "Epoch 17/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4202 - accuracy: 0.8531 - val_loss: 0.4021 - val_accuracy: 0.8593\n",
            "Epoch 18/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4153 - accuracy: 0.8535 - val_loss: 0.3995 - val_accuracy: 0.8622\n",
            "Epoch 19/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4108 - accuracy: 0.8561 - val_loss: 0.3921 - val_accuracy: 0.8628\n",
            "Epoch 20/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4043 - accuracy: 0.8578 - val_loss: 0.3897 - val_accuracy: 0.8639\n",
            "Epoch 21/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3971 - accuracy: 0.8615 - val_loss: 0.3865 - val_accuracy: 0.8641\n",
            "Epoch 22/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3956 - accuracy: 0.8608 - val_loss: 0.3875 - val_accuracy: 0.8640\n",
            "Epoch 23/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3908 - accuracy: 0.8614 - val_loss: 0.3814 - val_accuracy: 0.8650\n",
            "Epoch 24/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3880 - accuracy: 0.8628 - val_loss: 0.3765 - val_accuracy: 0.8687\n",
            "Epoch 25/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3829 - accuracy: 0.8658 - val_loss: 0.3740 - val_accuracy: 0.8686\n",
            "Epoch 26/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3781 - accuracy: 0.8659 - val_loss: 0.3707 - val_accuracy: 0.8694\n",
            "Epoch 27/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3760 - accuracy: 0.8676 - val_loss: 0.3697 - val_accuracy: 0.8694\n",
            "Epoch 28/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3715 - accuracy: 0.8672 - val_loss: 0.3676 - val_accuracy: 0.8703\n",
            "Epoch 29/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3688 - accuracy: 0.8681 - val_loss: 0.3642 - val_accuracy: 0.8718\n",
            "Epoch 30/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3658 - accuracy: 0.8702 - val_loss: 0.3626 - val_accuracy: 0.8718\n",
            "Epoch 31/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3619 - accuracy: 0.8716 - val_loss: 0.3604 - val_accuracy: 0.8723\n",
            "Epoch 32/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3592 - accuracy: 0.8720 - val_loss: 0.3592 - val_accuracy: 0.8733\n",
            "Epoch 33/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3562 - accuracy: 0.8731 - val_loss: 0.3571 - val_accuracy: 0.8735\n",
            "Epoch 34/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3544 - accuracy: 0.8737 - val_loss: 0.3563 - val_accuracy: 0.8728\n",
            "Epoch 35/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3499 - accuracy: 0.8756 - val_loss: 0.3545 - val_accuracy: 0.8737\n",
            "Epoch 36/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3495 - accuracy: 0.8748 - val_loss: 0.3501 - val_accuracy: 0.8775\n",
            "Epoch 37/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3455 - accuracy: 0.8762 - val_loss: 0.3498 - val_accuracy: 0.8763\n",
            "Epoch 38/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3446 - accuracy: 0.8758 - val_loss: 0.3473 - val_accuracy: 0.8763\n",
            "Epoch 39/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3421 - accuracy: 0.8776 - val_loss: 0.3474 - val_accuracy: 0.8771\n",
            "Epoch 40/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3412 - accuracy: 0.8775 - val_loss: 0.3452 - val_accuracy: 0.8771\n",
            "Epoch 41/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3377 - accuracy: 0.8795 - val_loss: 0.3478 - val_accuracy: 0.8773\n",
            "Epoch 42/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3339 - accuracy: 0.8808 - val_loss: 0.3429 - val_accuracy: 0.8787\n",
            "Epoch 43/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3322 - accuracy: 0.8814 - val_loss: 0.3417 - val_accuracy: 0.8794\n",
            "Epoch 44/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3306 - accuracy: 0.8816 - val_loss: 0.3397 - val_accuracy: 0.8795\n",
            "Epoch 45/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3273 - accuracy: 0.8828 - val_loss: 0.3424 - val_accuracy: 0.8788\n",
            "Epoch 46/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3272 - accuracy: 0.8822 - val_loss: 0.3362 - val_accuracy: 0.8811\n",
            "Epoch 47/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3240 - accuracy: 0.8835 - val_loss: 0.3369 - val_accuracy: 0.8807\n",
            "Epoch 48/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3221 - accuracy: 0.8855 - val_loss: 0.3365 - val_accuracy: 0.8794\n",
            "Epoch 49/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3198 - accuracy: 0.8855 - val_loss: 0.3335 - val_accuracy: 0.8811\n",
            "Epoch 50/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3179 - accuracy: 0.8860 - val_loss: 0.3362 - val_accuracy: 0.8807\n",
            "Epoch 51/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3163 - accuracy: 0.8875 - val_loss: 0.3304 - val_accuracy: 0.8835\n",
            "Epoch 52/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3123 - accuracy: 0.8880 - val_loss: 0.3294 - val_accuracy: 0.8824\n",
            "Epoch 53/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3125 - accuracy: 0.8881 - val_loss: 0.3328 - val_accuracy: 0.8823\n",
            "Epoch 54/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3123 - accuracy: 0.8872 - val_loss: 0.3275 - val_accuracy: 0.8830\n",
            "Epoch 55/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3077 - accuracy: 0.8885 - val_loss: 0.3283 - val_accuracy: 0.8824\n",
            "Epoch 56/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3069 - accuracy: 0.8903 - val_loss: 0.3269 - val_accuracy: 0.8836\n",
            "Epoch 57/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3066 - accuracy: 0.8911 - val_loss: 0.3243 - val_accuracy: 0.8846\n",
            "Epoch 58/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3031 - accuracy: 0.8910 - val_loss: 0.3236 - val_accuracy: 0.8853\n",
            "Epoch 59/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3019 - accuracy: 0.8922 - val_loss: 0.3236 - val_accuracy: 0.8848\n",
            "Epoch 60/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3002 - accuracy: 0.8928 - val_loss: 0.3225 - val_accuracy: 0.8852\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3465 - accuracy: 0.8758\n",
            "0.8758000135421753\n",
            "Accuracy: 87.58%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os, random\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "os.path.expanduser = lambda path: './'\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 60\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# for reproducibility\n",
        "import random, os\n",
        "os.environ['PYTHONHASHSEED']='0'\n",
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)\n",
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
        "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
        "from tensorflow.python.keras import backend as K\n",
        "K.set_session(sess)\n",
        "\n",
        "kernel_initializer='glorot_uniform'\n",
        "activation_function = 'relu'\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
        "print(metrics[1])\n",
        "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-ofXNgLF5xx"
      },
      "source": [
        "# Drop Out ( 0.5 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UtqDqCxtGLAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55ef908-4046-450e-b4dc-d052f16250e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 1.4219 - accuracy: 0.5106 - val_loss: 0.8142 - val_accuracy: 0.7203\n",
            "Epoch 2/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.9018 - accuracy: 0.6828 - val_loss: 0.6747 - val_accuracy: 0.7588\n",
            "Epoch 3/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.7783 - accuracy: 0.7287 - val_loss: 0.6098 - val_accuracy: 0.7837\n",
            "Epoch 4/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.7092 - accuracy: 0.7528 - val_loss: 0.5698 - val_accuracy: 0.7997\n",
            "Epoch 5/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6587 - accuracy: 0.7707 - val_loss: 0.5365 - val_accuracy: 0.8122\n",
            "Epoch 6/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6228 - accuracy: 0.7840 - val_loss: 0.5160 - val_accuracy: 0.8208\n",
            "Epoch 7/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5972 - accuracy: 0.7931 - val_loss: 0.4992 - val_accuracy: 0.8244\n",
            "Epoch 8/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5742 - accuracy: 0.7992 - val_loss: 0.4848 - val_accuracy: 0.8306\n",
            "Epoch 9/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.5572 - accuracy: 0.8059 - val_loss: 0.4751 - val_accuracy: 0.8289\n",
            "Epoch 10/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5412 - accuracy: 0.8110 - val_loss: 0.4651 - val_accuracy: 0.8342\n",
            "Epoch 11/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5315 - accuracy: 0.8149 - val_loss: 0.4546 - val_accuracy: 0.8392\n",
            "Epoch 12/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.5197 - accuracy: 0.8177 - val_loss: 0.4466 - val_accuracy: 0.8397\n",
            "Epoch 13/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5032 - accuracy: 0.8227 - val_loss: 0.4397 - val_accuracy: 0.8427\n",
            "Epoch 14/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4984 - accuracy: 0.8245 - val_loss: 0.4330 - val_accuracy: 0.8452\n",
            "Epoch 15/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4922 - accuracy: 0.8259 - val_loss: 0.4258 - val_accuracy: 0.8467\n",
            "Epoch 16/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4847 - accuracy: 0.8296 - val_loss: 0.4244 - val_accuracy: 0.8493\n",
            "Epoch 17/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4744 - accuracy: 0.8321 - val_loss: 0.4169 - val_accuracy: 0.8508\n",
            "Epoch 18/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4712 - accuracy: 0.8333 - val_loss: 0.4138 - val_accuracy: 0.8531\n",
            "Epoch 19/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4658 - accuracy: 0.8351 - val_loss: 0.4091 - val_accuracy: 0.8533\n",
            "Epoch 20/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4589 - accuracy: 0.8386 - val_loss: 0.4060 - val_accuracy: 0.8554\n",
            "Epoch 21/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4501 - accuracy: 0.8405 - val_loss: 0.4036 - val_accuracy: 0.8540\n",
            "Epoch 22/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4486 - accuracy: 0.8415 - val_loss: 0.3996 - val_accuracy: 0.8569\n",
            "Epoch 23/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4442 - accuracy: 0.8430 - val_loss: 0.3961 - val_accuracy: 0.8586\n",
            "Epoch 24/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4401 - accuracy: 0.8443 - val_loss: 0.3916 - val_accuracy: 0.8595\n",
            "Epoch 25/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4359 - accuracy: 0.8445 - val_loss: 0.3889 - val_accuracy: 0.8608\n",
            "Epoch 26/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4301 - accuracy: 0.8465 - val_loss: 0.3865 - val_accuracy: 0.8608\n",
            "Epoch 27/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4295 - accuracy: 0.8471 - val_loss: 0.3844 - val_accuracy: 0.8622\n",
            "Epoch 28/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4217 - accuracy: 0.8504 - val_loss: 0.3817 - val_accuracy: 0.8631\n",
            "Epoch 29/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4208 - accuracy: 0.8498 - val_loss: 0.3781 - val_accuracy: 0.8652\n",
            "Epoch 30/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4167 - accuracy: 0.8532 - val_loss: 0.3776 - val_accuracy: 0.8642\n",
            "Epoch 31/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4153 - accuracy: 0.8522 - val_loss: 0.3757 - val_accuracy: 0.8641\n",
            "Epoch 32/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4104 - accuracy: 0.8548 - val_loss: 0.3738 - val_accuracy: 0.8652\n",
            "Epoch 33/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4060 - accuracy: 0.8561 - val_loss: 0.3709 - val_accuracy: 0.8653\n",
            "Epoch 34/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4048 - accuracy: 0.8564 - val_loss: 0.3701 - val_accuracy: 0.8660\n",
            "Epoch 35/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4024 - accuracy: 0.8568 - val_loss: 0.3681 - val_accuracy: 0.8681\n",
            "Epoch 36/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3978 - accuracy: 0.8592 - val_loss: 0.3647 - val_accuracy: 0.8687\n",
            "Epoch 37/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3969 - accuracy: 0.8582 - val_loss: 0.3649 - val_accuracy: 0.8685\n",
            "Epoch 38/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3959 - accuracy: 0.8597 - val_loss: 0.3615 - val_accuracy: 0.8692\n",
            "Epoch 39/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3931 - accuracy: 0.8597 - val_loss: 0.3605 - val_accuracy: 0.8705\n",
            "Epoch 40/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3897 - accuracy: 0.8593 - val_loss: 0.3581 - val_accuracy: 0.8703\n",
            "Epoch 41/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3869 - accuracy: 0.8624 - val_loss: 0.3587 - val_accuracy: 0.8701\n",
            "Epoch 42/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3846 - accuracy: 0.8636 - val_loss: 0.3555 - val_accuracy: 0.8723\n",
            "Epoch 43/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3823 - accuracy: 0.8630 - val_loss: 0.3542 - val_accuracy: 0.8714\n",
            "Epoch 44/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3816 - accuracy: 0.8636 - val_loss: 0.3530 - val_accuracy: 0.8733\n",
            "Epoch 45/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3789 - accuracy: 0.8648 - val_loss: 0.3522 - val_accuracy: 0.8750\n",
            "Epoch 46/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3758 - accuracy: 0.8659 - val_loss: 0.3495 - val_accuracy: 0.8749\n",
            "Epoch 47/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3727 - accuracy: 0.8667 - val_loss: 0.3506 - val_accuracy: 0.8729\n",
            "Epoch 48/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3721 - accuracy: 0.8667 - val_loss: 0.3482 - val_accuracy: 0.8748\n",
            "Epoch 49/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3714 - accuracy: 0.8667 - val_loss: 0.3460 - val_accuracy: 0.8767\n",
            "Epoch 50/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3689 - accuracy: 0.8679 - val_loss: 0.3478 - val_accuracy: 0.8747\n",
            "Epoch 51/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3666 - accuracy: 0.8686 - val_loss: 0.3430 - val_accuracy: 0.8780\n",
            "Epoch 52/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3668 - accuracy: 0.8690 - val_loss: 0.3437 - val_accuracy: 0.8768\n",
            "Epoch 53/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3617 - accuracy: 0.8701 - val_loss: 0.3445 - val_accuracy: 0.8757\n",
            "Epoch 54/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3616 - accuracy: 0.8698 - val_loss: 0.3415 - val_accuracy: 0.8763\n",
            "Epoch 55/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3603 - accuracy: 0.8714 - val_loss: 0.3410 - val_accuracy: 0.8759\n",
            "Epoch 56/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3565 - accuracy: 0.8717 - val_loss: 0.3390 - val_accuracy: 0.8782\n",
            "Epoch 57/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3590 - accuracy: 0.8711 - val_loss: 0.3378 - val_accuracy: 0.8785\n",
            "Epoch 58/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3547 - accuracy: 0.8725 - val_loss: 0.3367 - val_accuracy: 0.8797\n",
            "Epoch 59/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3511 - accuracy: 0.8735 - val_loss: 0.3359 - val_accuracy: 0.8788\n",
            "Epoch 60/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3515 - accuracy: 0.8743 - val_loss: 0.3346 - val_accuracy: 0.8799\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3615 - accuracy: 0.8699\n",
            "0.8698999881744385\n",
            "Accuracy: 86.99%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os, random\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "os.path.expanduser = lambda path: './'\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 60\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# for reproducibility\n",
        "import random, os\n",
        "os.environ['PYTHONHASHSEED']='0'\n",
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)\n",
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
        "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
        "from tensorflow.python.keras import backend as K\n",
        "K.set_session(sess)\n",
        "\n",
        "kernel_initializer='glorot_uniform'\n",
        "activation_function = 'relu'\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
        "print(metrics[1])\n",
        "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7OZtNdvF84w"
      },
      "source": [
        "# Drop Out ( 0.8 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_mSCVGzIHtth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b33f561-e207-4746-b466-578cecefc5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 1.9859 - accuracy: 0.2964 - val_loss: 1.2486 - val_accuracy: 0.6500\n",
            "Epoch 2/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 1.3898 - accuracy: 0.4929 - val_loss: 0.9011 - val_accuracy: 0.6886\n",
            "Epoch 3/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 1.1611 - accuracy: 0.5705 - val_loss: 0.7840 - val_accuracy: 0.7178\n",
            "Epoch 4/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 1.0343 - accuracy: 0.6178 - val_loss: 0.7244 - val_accuracy: 0.7373\n",
            "Epoch 5/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.9532 - accuracy: 0.6459 - val_loss: 0.6812 - val_accuracy: 0.7558\n",
            "Epoch 6/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.8955 - accuracy: 0.6675 - val_loss: 0.6516 - val_accuracy: 0.7632\n",
            "Epoch 7/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.8534 - accuracy: 0.6860 - val_loss: 0.6259 - val_accuracy: 0.7743\n",
            "Epoch 8/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.8171 - accuracy: 0.6995 - val_loss: 0.6074 - val_accuracy: 0.7812\n",
            "Epoch 9/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.7927 - accuracy: 0.7101 - val_loss: 0.5903 - val_accuracy: 0.7904\n",
            "Epoch 10/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.7607 - accuracy: 0.7202 - val_loss: 0.5747 - val_accuracy: 0.7931\n",
            "Epoch 11/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.7475 - accuracy: 0.7287 - val_loss: 0.5602 - val_accuracy: 0.8015\n",
            "Epoch 12/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.7281 - accuracy: 0.7381 - val_loss: 0.5479 - val_accuracy: 0.8055\n",
            "Epoch 13/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.7099 - accuracy: 0.7452 - val_loss: 0.5350 - val_accuracy: 0.8127\n",
            "Epoch 14/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6943 - accuracy: 0.7506 - val_loss: 0.5294 - val_accuracy: 0.8158\n",
            "Epoch 15/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6852 - accuracy: 0.7546 - val_loss: 0.5186 - val_accuracy: 0.8215\n",
            "Epoch 16/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6777 - accuracy: 0.7583 - val_loss: 0.5154 - val_accuracy: 0.8209\n",
            "Epoch 17/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6571 - accuracy: 0.7663 - val_loss: 0.5041 - val_accuracy: 0.8238\n",
            "Epoch 18/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6533 - accuracy: 0.7684 - val_loss: 0.4979 - val_accuracy: 0.8274\n",
            "Epoch 19/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6393 - accuracy: 0.7696 - val_loss: 0.4922 - val_accuracy: 0.8296\n",
            "Epoch 20/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6312 - accuracy: 0.7764 - val_loss: 0.4869 - val_accuracy: 0.8308\n",
            "Epoch 21/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6201 - accuracy: 0.7796 - val_loss: 0.4805 - val_accuracy: 0.8299\n",
            "Epoch 22/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6150 - accuracy: 0.7829 - val_loss: 0.4770 - val_accuracy: 0.8336\n",
            "Epoch 23/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6105 - accuracy: 0.7844 - val_loss: 0.4717 - val_accuracy: 0.8361\n",
            "Epoch 24/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.6065 - accuracy: 0.7878 - val_loss: 0.4687 - val_accuracy: 0.8358\n",
            "Epoch 25/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5977 - accuracy: 0.7925 - val_loss: 0.4632 - val_accuracy: 0.8360\n",
            "Epoch 26/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5947 - accuracy: 0.7900 - val_loss: 0.4596 - val_accuracy: 0.8387\n",
            "Epoch 27/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5879 - accuracy: 0.7938 - val_loss: 0.4568 - val_accuracy: 0.8375\n",
            "Epoch 28/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.5793 - accuracy: 0.7970 - val_loss: 0.4554 - val_accuracy: 0.8415\n",
            "Epoch 29/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.5792 - accuracy: 0.7968 - val_loss: 0.4510 - val_accuracy: 0.8413\n",
            "Epoch 30/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5723 - accuracy: 0.8000 - val_loss: 0.4467 - val_accuracy: 0.8411\n",
            "Epoch 31/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5692 - accuracy: 0.8004 - val_loss: 0.4430 - val_accuracy: 0.8427\n",
            "Epoch 32/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5622 - accuracy: 0.8055 - val_loss: 0.4423 - val_accuracy: 0.8433\n",
            "Epoch 33/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5609 - accuracy: 0.8043 - val_loss: 0.4377 - val_accuracy: 0.8441\n",
            "Epoch 34/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5558 - accuracy: 0.8061 - val_loss: 0.4366 - val_accuracy: 0.8443\n",
            "Epoch 35/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.5476 - accuracy: 0.8081 - val_loss: 0.4352 - val_accuracy: 0.8457\n",
            "Epoch 36/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5454 - accuracy: 0.8099 - val_loss: 0.4315 - val_accuracy: 0.8452\n",
            "Epoch 37/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.5453 - accuracy: 0.8083 - val_loss: 0.4304 - val_accuracy: 0.8462\n",
            "Epoch 38/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.5402 - accuracy: 0.8095 - val_loss: 0.4300 - val_accuracy: 0.8462\n",
            "Epoch 39/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5388 - accuracy: 0.8127 - val_loss: 0.4294 - val_accuracy: 0.8480\n",
            "Epoch 40/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5370 - accuracy: 0.8116 - val_loss: 0.4270 - val_accuracy: 0.8495\n",
            "Epoch 41/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5335 - accuracy: 0.8152 - val_loss: 0.4235 - val_accuracy: 0.8512\n",
            "Epoch 42/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5325 - accuracy: 0.8163 - val_loss: 0.4227 - val_accuracy: 0.8500\n",
            "Epoch 43/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5273 - accuracy: 0.8174 - val_loss: 0.4204 - val_accuracy: 0.8512\n",
            "Epoch 44/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5249 - accuracy: 0.8165 - val_loss: 0.4201 - val_accuracy: 0.8508\n",
            "Epoch 45/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5210 - accuracy: 0.8176 - val_loss: 0.4181 - val_accuracy: 0.8504\n",
            "Epoch 46/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5145 - accuracy: 0.8212 - val_loss: 0.4170 - val_accuracy: 0.8519\n",
            "Epoch 47/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5146 - accuracy: 0.8196 - val_loss: 0.4129 - val_accuracy: 0.8526\n",
            "Epoch 48/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5121 - accuracy: 0.8201 - val_loss: 0.4131 - val_accuracy: 0.8522\n",
            "Epoch 49/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5138 - accuracy: 0.8213 - val_loss: 0.4105 - val_accuracy: 0.8549\n",
            "Epoch 50/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5069 - accuracy: 0.8250 - val_loss: 0.4117 - val_accuracy: 0.8533\n",
            "Epoch 51/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5073 - accuracy: 0.8236 - val_loss: 0.4097 - val_accuracy: 0.8538\n",
            "Epoch 52/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5088 - accuracy: 0.8223 - val_loss: 0.4082 - val_accuracy: 0.8543\n",
            "Epoch 53/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5004 - accuracy: 0.8247 - val_loss: 0.4077 - val_accuracy: 0.8539\n",
            "Epoch 54/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.5002 - accuracy: 0.8237 - val_loss: 0.4036 - val_accuracy: 0.8556\n",
            "Epoch 55/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.5005 - accuracy: 0.8267 - val_loss: 0.4044 - val_accuracy: 0.8566\n",
            "Epoch 56/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4968 - accuracy: 0.8267 - val_loss: 0.4031 - val_accuracy: 0.8578\n",
            "Epoch 57/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4949 - accuracy: 0.8288 - val_loss: 0.4002 - val_accuracy: 0.8572\n",
            "Epoch 58/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4920 - accuracy: 0.8287 - val_loss: 0.4001 - val_accuracy: 0.8583\n",
            "Epoch 59/60\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.4883 - accuracy: 0.8300 - val_loss: 0.3994 - val_accuracy: 0.8590\n",
            "Epoch 60/60\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.4879 - accuracy: 0.8299 - val_loss: 0.3975 - val_accuracy: 0.8594\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4214 - accuracy: 0.8482\n",
            "0.8482000231742859\n",
            "Accuracy: 84.82%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os, random\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "os.path.expanduser = lambda path: './'\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 60\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# for reproducibility\n",
        "import random, os\n",
        "os.environ['PYTHONHASHSEED']='0'\n",
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)\n",
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
        "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
        "from tensorflow.python.keras import backend as K\n",
        "K.set_session(sess)\n",
        "\n",
        "kernel_initializer='glorot_uniform'\n",
        "activation_function = 'relu'\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "    model.add(Dropout(0.8))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.8))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
        "print(metrics[1])\n",
        "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc3bLuowFuei"
      },
      "source": [
        "# Batch Normalization ( 0.2 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wnNf_e4UFxuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "590a50b5-deaf-4cc8-b21e-e5196fb822e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 512)              2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 673,802\n",
            "Trainable params: 671,754\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "375/375 [==============================] - 8s 19ms/step - loss: 0.7242 - accuracy: 0.7479 - val_loss: 0.5086 - val_accuracy: 0.8233\n",
            "Epoch 2/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.5068 - accuracy: 0.8200 - val_loss: 0.4157 - val_accuracy: 0.8520\n",
            "Epoch 3/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4545 - accuracy: 0.8374 - val_loss: 0.3847 - val_accuracy: 0.8643\n",
            "Epoch 4/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4220 - accuracy: 0.8496 - val_loss: 0.3689 - val_accuracy: 0.8689\n",
            "Epoch 5/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4015 - accuracy: 0.8556 - val_loss: 0.3616 - val_accuracy: 0.8708\n",
            "Epoch 6/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3832 - accuracy: 0.8621 - val_loss: 0.3477 - val_accuracy: 0.8748\n",
            "Epoch 7/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3691 - accuracy: 0.8677 - val_loss: 0.3442 - val_accuracy: 0.8769\n",
            "Epoch 8/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3562 - accuracy: 0.8692 - val_loss: 0.3462 - val_accuracy: 0.8780\n",
            "Epoch 9/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3451 - accuracy: 0.8738 - val_loss: 0.3357 - val_accuracy: 0.8811\n",
            "Epoch 10/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3369 - accuracy: 0.8771 - val_loss: 0.3296 - val_accuracy: 0.8821\n",
            "Epoch 11/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3308 - accuracy: 0.8784 - val_loss: 0.3279 - val_accuracy: 0.8830\n",
            "Epoch 12/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3185 - accuracy: 0.8843 - val_loss: 0.3221 - val_accuracy: 0.8840\n",
            "Epoch 13/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3111 - accuracy: 0.8860 - val_loss: 0.3203 - val_accuracy: 0.8845\n",
            "Epoch 14/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3076 - accuracy: 0.8881 - val_loss: 0.3221 - val_accuracy: 0.8841\n",
            "Epoch 15/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2970 - accuracy: 0.8898 - val_loss: 0.3109 - val_accuracy: 0.8863\n",
            "Epoch 16/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2953 - accuracy: 0.8903 - val_loss: 0.3160 - val_accuracy: 0.8852\n",
            "Epoch 17/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2874 - accuracy: 0.8942 - val_loss: 0.3089 - val_accuracy: 0.8870\n",
            "Epoch 18/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2818 - accuracy: 0.8949 - val_loss: 0.3088 - val_accuracy: 0.8905\n",
            "Epoch 19/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2774 - accuracy: 0.8994 - val_loss: 0.3055 - val_accuracy: 0.8883\n",
            "Epoch 20/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2731 - accuracy: 0.8996 - val_loss: 0.3064 - val_accuracy: 0.8875\n",
            "Epoch 21/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2643 - accuracy: 0.9017 - val_loss: 0.3060 - val_accuracy: 0.8899\n",
            "Epoch 22/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2628 - accuracy: 0.9032 - val_loss: 0.3147 - val_accuracy: 0.8851\n",
            "Epoch 23/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2588 - accuracy: 0.9051 - val_loss: 0.3025 - val_accuracy: 0.8903\n",
            "Epoch 24/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2518 - accuracy: 0.9075 - val_loss: 0.3055 - val_accuracy: 0.8892\n",
            "Epoch 25/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2486 - accuracy: 0.9076 - val_loss: 0.3030 - val_accuracy: 0.8917\n",
            "Epoch 26/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2430 - accuracy: 0.9096 - val_loss: 0.3053 - val_accuracy: 0.8913\n",
            "Epoch 27/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2413 - accuracy: 0.9115 - val_loss: 0.3025 - val_accuracy: 0.8916\n",
            "Epoch 28/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2361 - accuracy: 0.9130 - val_loss: 0.3069 - val_accuracy: 0.8895\n",
            "Epoch 29/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2319 - accuracy: 0.9142 - val_loss: 0.3031 - val_accuracy: 0.8917\n",
            "Epoch 30/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2280 - accuracy: 0.9153 - val_loss: 0.3030 - val_accuracy: 0.8914\n",
            "Epoch 31/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2241 - accuracy: 0.9173 - val_loss: 0.3022 - val_accuracy: 0.8927\n",
            "Epoch 32/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2212 - accuracy: 0.9183 - val_loss: 0.3007 - val_accuracy: 0.8938\n",
            "Epoch 33/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2221 - accuracy: 0.9171 - val_loss: 0.2954 - val_accuracy: 0.8951\n",
            "Epoch 34/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2189 - accuracy: 0.9192 - val_loss: 0.3041 - val_accuracy: 0.8925\n",
            "Epoch 35/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2120 - accuracy: 0.9214 - val_loss: 0.3012 - val_accuracy: 0.8931\n",
            "Epoch 36/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2101 - accuracy: 0.9218 - val_loss: 0.2985 - val_accuracy: 0.8957\n",
            "Epoch 37/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2082 - accuracy: 0.9226 - val_loss: 0.3017 - val_accuracy: 0.8926\n",
            "Epoch 38/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2068 - accuracy: 0.9229 - val_loss: 0.3012 - val_accuracy: 0.8920\n",
            "Epoch 39/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2007 - accuracy: 0.9255 - val_loss: 0.3035 - val_accuracy: 0.8928\n",
            "Epoch 40/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2008 - accuracy: 0.9259 - val_loss: 0.3058 - val_accuracy: 0.8922\n",
            "Epoch 41/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1968 - accuracy: 0.9272 - val_loss: 0.3012 - val_accuracy: 0.8937\n",
            "Epoch 42/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1926 - accuracy: 0.9291 - val_loss: 0.3054 - val_accuracy: 0.8935\n",
            "Epoch 43/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1903 - accuracy: 0.9298 - val_loss: 0.3045 - val_accuracy: 0.8944\n",
            "Epoch 44/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1884 - accuracy: 0.9298 - val_loss: 0.3097 - val_accuracy: 0.8926\n",
            "Epoch 45/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1852 - accuracy: 0.9311 - val_loss: 0.3142 - val_accuracy: 0.8930\n",
            "Epoch 46/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1842 - accuracy: 0.9307 - val_loss: 0.3139 - val_accuracy: 0.8913\n",
            "Epoch 47/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1797 - accuracy: 0.9329 - val_loss: 0.3073 - val_accuracy: 0.8937\n",
            "Epoch 48/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1788 - accuracy: 0.9340 - val_loss: 0.3119 - val_accuracy: 0.8929\n",
            "Epoch 49/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1753 - accuracy: 0.9350 - val_loss: 0.3123 - val_accuracy: 0.8916\n",
            "Epoch 50/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1722 - accuracy: 0.9361 - val_loss: 0.3127 - val_accuracy: 0.8923\n",
            "Epoch 51/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1726 - accuracy: 0.9361 - val_loss: 0.3108 - val_accuracy: 0.8924\n",
            "Epoch 52/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1678 - accuracy: 0.9365 - val_loss: 0.3058 - val_accuracy: 0.8958\n",
            "Epoch 53/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.1659 - accuracy: 0.9389 - val_loss: 0.3228 - val_accuracy: 0.8908\n",
            "Epoch 54/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.1640 - accuracy: 0.9387 - val_loss: 0.3060 - val_accuracy: 0.8972\n",
            "Epoch 55/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1624 - accuracy: 0.9392 - val_loss: 0.3166 - val_accuracy: 0.8952\n",
            "Epoch 56/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1626 - accuracy: 0.9404 - val_loss: 0.3148 - val_accuracy: 0.8934\n",
            "Epoch 57/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1571 - accuracy: 0.9420 - val_loss: 0.3173 - val_accuracy: 0.8932\n",
            "Epoch 58/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1577 - accuracy: 0.9418 - val_loss: 0.3162 - val_accuracy: 0.8950\n",
            "Epoch 59/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1533 - accuracy: 0.9431 - val_loss: 0.3221 - val_accuracy: 0.8919\n",
            "Epoch 60/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1555 - accuracy: 0.9437 - val_loss: 0.3256 - val_accuracy: 0.8903\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3465 - accuracy: 0.8867\n",
            "0.8866999745368958\n",
            "Accuracy: 88.67%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os, random\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "os.path.expanduser = lambda path: './'\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 60\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# for reproducibility\n",
        "import random, os\n",
        "os.environ['PYTHONHASHSEED']='0'\n",
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)\n",
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
        "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
        "from tensorflow.python.keras import backend as K\n",
        "K.set_session(sess)\n",
        "\n",
        "kernel_initializer='glorot_uniform'\n",
        "activation_function = 'relu'\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
        "print(metrics[1])\n",
        "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASRWbM4JGB5U"
      },
      "source": [
        "# Batch Normalization ( 0.5 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "os.path.expanduser = lambda path: './'\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 60\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# for reproducibility\n",
        "import random, os\n",
        "os.environ['PYTHONHASHSEED']='0'\n",
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)\n",
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
        "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
        "from tensorflow.python.keras import backend as K\n",
        "K.set_session(sess)\n",
        "\n",
        "kernel_initializer='glorot_uniform'\n",
        "activation_function = 'relu'\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
        "print(metrics[1])\n",
        "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5chn_1MKhyrC",
        "outputId": "a44cd8a4-e172-4153-f937-62c735403241"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 673,802\n",
            "Trainable params: 671,754\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "375/375 [==============================] - 8s 19ms/step - loss: 1.0646 - accuracy: 0.6356 - val_loss: 0.6020 - val_accuracy: 0.7915\n",
            "Epoch 2/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.6906 - accuracy: 0.7573 - val_loss: 0.4844 - val_accuracy: 0.8266\n",
            "Epoch 3/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.6125 - accuracy: 0.7829 - val_loss: 0.4513 - val_accuracy: 0.8378\n",
            "Epoch 4/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.5676 - accuracy: 0.7994 - val_loss: 0.4354 - val_accuracy: 0.8435\n",
            "Epoch 5/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.5372 - accuracy: 0.8092 - val_loss: 0.4159 - val_accuracy: 0.8498\n",
            "Epoch 6/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5135 - accuracy: 0.8180 - val_loss: 0.4061 - val_accuracy: 0.8547\n",
            "Epoch 7/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4931 - accuracy: 0.8245 - val_loss: 0.4017 - val_accuracy: 0.8555\n",
            "Epoch 8/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4798 - accuracy: 0.8290 - val_loss: 0.3914 - val_accuracy: 0.8603\n",
            "Epoch 9/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.4665 - accuracy: 0.8335 - val_loss: 0.3851 - val_accuracy: 0.8612\n",
            "Epoch 10/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4553 - accuracy: 0.8377 - val_loss: 0.3816 - val_accuracy: 0.8637\n",
            "Epoch 11/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4492 - accuracy: 0.8381 - val_loss: 0.3743 - val_accuracy: 0.8640\n",
            "Epoch 12/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4384 - accuracy: 0.8442 - val_loss: 0.3674 - val_accuracy: 0.8662\n",
            "Epoch 13/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4261 - accuracy: 0.8455 - val_loss: 0.3646 - val_accuracy: 0.8668\n",
            "Epoch 14/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4245 - accuracy: 0.8477 - val_loss: 0.3671 - val_accuracy: 0.8658\n",
            "Epoch 15/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4170 - accuracy: 0.8495 - val_loss: 0.3594 - val_accuracy: 0.8717\n",
            "Epoch 16/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4136 - accuracy: 0.8521 - val_loss: 0.3599 - val_accuracy: 0.8698\n",
            "Epoch 17/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4053 - accuracy: 0.8537 - val_loss: 0.3530 - val_accuracy: 0.8737\n",
            "Epoch 18/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4028 - accuracy: 0.8565 - val_loss: 0.3497 - val_accuracy: 0.8733\n",
            "Epoch 19/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3990 - accuracy: 0.8580 - val_loss: 0.3480 - val_accuracy: 0.8756\n",
            "Epoch 20/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3930 - accuracy: 0.8585 - val_loss: 0.3497 - val_accuracy: 0.8711\n",
            "Epoch 21/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3841 - accuracy: 0.8624 - val_loss: 0.3450 - val_accuracy: 0.8773\n",
            "Epoch 22/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3845 - accuracy: 0.8606 - val_loss: 0.3442 - val_accuracy: 0.8766\n",
            "Epoch 23/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3806 - accuracy: 0.8635 - val_loss: 0.3406 - val_accuracy: 0.8773\n",
            "Epoch 24/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3731 - accuracy: 0.8652 - val_loss: 0.3363 - val_accuracy: 0.8789\n",
            "Epoch 25/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3720 - accuracy: 0.8649 - val_loss: 0.3382 - val_accuracy: 0.8777\n",
            "Epoch 26/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3686 - accuracy: 0.8663 - val_loss: 0.3321 - val_accuracy: 0.8802\n",
            "Epoch 27/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3643 - accuracy: 0.8686 - val_loss: 0.3337 - val_accuracy: 0.8798\n",
            "Epoch 28/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3573 - accuracy: 0.8719 - val_loss: 0.3337 - val_accuracy: 0.8799\n",
            "Epoch 29/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3589 - accuracy: 0.8704 - val_loss: 0.3292 - val_accuracy: 0.8809\n",
            "Epoch 30/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3567 - accuracy: 0.8720 - val_loss: 0.3330 - val_accuracy: 0.8793\n",
            "Epoch 31/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3526 - accuracy: 0.8723 - val_loss: 0.3309 - val_accuracy: 0.8788\n",
            "Epoch 32/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3526 - accuracy: 0.8724 - val_loss: 0.3301 - val_accuracy: 0.8808\n",
            "Epoch 33/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.3456 - accuracy: 0.8757 - val_loss: 0.3251 - val_accuracy: 0.8829\n",
            "Epoch 34/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.3450 - accuracy: 0.8744 - val_loss: 0.3271 - val_accuracy: 0.8805\n",
            "Epoch 35/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3405 - accuracy: 0.8752 - val_loss: 0.3266 - val_accuracy: 0.8811\n",
            "Epoch 36/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3408 - accuracy: 0.8761 - val_loss: 0.3250 - val_accuracy: 0.8818\n",
            "Epoch 37/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3397 - accuracy: 0.8774 - val_loss: 0.3226 - val_accuracy: 0.8832\n",
            "Epoch 38/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3376 - accuracy: 0.8781 - val_loss: 0.3217 - val_accuracy: 0.8838\n",
            "Epoch 39/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3312 - accuracy: 0.8796 - val_loss: 0.3207 - val_accuracy: 0.8832\n",
            "Epoch 40/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3301 - accuracy: 0.8780 - val_loss: 0.3212 - val_accuracy: 0.8842\n",
            "Epoch 41/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3282 - accuracy: 0.8795 - val_loss: 0.3184 - val_accuracy: 0.8852\n",
            "Epoch 42/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3241 - accuracy: 0.8828 - val_loss: 0.3137 - val_accuracy: 0.8864\n",
            "Epoch 43/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3211 - accuracy: 0.8821 - val_loss: 0.3142 - val_accuracy: 0.8857\n",
            "Epoch 44/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3200 - accuracy: 0.8832 - val_loss: 0.3170 - val_accuracy: 0.8856\n",
            "Epoch 45/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3183 - accuracy: 0.8832 - val_loss: 0.3192 - val_accuracy: 0.8852\n",
            "Epoch 46/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3177 - accuracy: 0.8848 - val_loss: 0.3139 - val_accuracy: 0.8862\n",
            "Epoch 47/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3130 - accuracy: 0.8856 - val_loss: 0.3174 - val_accuracy: 0.8839\n",
            "Epoch 48/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3089 - accuracy: 0.8856 - val_loss: 0.3159 - val_accuracy: 0.8868\n",
            "Epoch 49/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3091 - accuracy: 0.8860 - val_loss: 0.3118 - val_accuracy: 0.8873\n",
            "Epoch 50/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3105 - accuracy: 0.8865 - val_loss: 0.3154 - val_accuracy: 0.8848\n",
            "Epoch 51/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3074 - accuracy: 0.8874 - val_loss: 0.3125 - val_accuracy: 0.8860\n",
            "Epoch 52/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3055 - accuracy: 0.8880 - val_loss: 0.3086 - val_accuracy: 0.8892\n",
            "Epoch 53/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3016 - accuracy: 0.8896 - val_loss: 0.3191 - val_accuracy: 0.8852\n",
            "Epoch 54/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3016 - accuracy: 0.8894 - val_loss: 0.3105 - val_accuracy: 0.8879\n",
            "Epoch 55/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3012 - accuracy: 0.8900 - val_loss: 0.3127 - val_accuracy: 0.8885\n",
            "Epoch 56/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2972 - accuracy: 0.8913 - val_loss: 0.3072 - val_accuracy: 0.8889\n",
            "Epoch 57/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.2992 - accuracy: 0.8901 - val_loss: 0.3078 - val_accuracy: 0.8872\n",
            "Epoch 58/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2946 - accuracy: 0.8915 - val_loss: 0.3061 - val_accuracy: 0.8891\n",
            "Epoch 59/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2927 - accuracy: 0.8902 - val_loss: 0.3076 - val_accuracy: 0.8881\n",
            "Epoch 60/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.2944 - accuracy: 0.8924 - val_loss: 0.3073 - val_accuracy: 0.8898\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3318 - accuracy: 0.8827\n",
            "0.8827000260353088\n",
            "Accuracy: 88.27%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpw_gY6hGELD"
      },
      "source": [
        "# Batch Normalization ( 0.8 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sz-jAgIEGDn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93b79f4-2372-4cd1-95fb-5e39a1753b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 673,802\n",
            "Trainable params: 671,754\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "375/375 [==============================] - 8s 19ms/step - loss: 2.0176 - accuracy: 0.3185 - val_loss: 1.0184 - val_accuracy: 0.6819\n",
            "Epoch 2/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.3015 - accuracy: 0.5313 - val_loss: 0.7802 - val_accuracy: 0.7398\n",
            "Epoch 3/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.0816 - accuracy: 0.6010 - val_loss: 0.6985 - val_accuracy: 0.7485\n",
            "Epoch 4/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9756 - accuracy: 0.6420 - val_loss: 0.6683 - val_accuracy: 0.7616\n",
            "Epoch 5/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.8939 - accuracy: 0.6702 - val_loss: 0.6359 - val_accuracy: 0.7756\n",
            "Epoch 6/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.8482 - accuracy: 0.6898 - val_loss: 0.6152 - val_accuracy: 0.7814\n",
            "Epoch 7/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.8085 - accuracy: 0.7056 - val_loss: 0.5934 - val_accuracy: 0.7889\n",
            "Epoch 8/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.7812 - accuracy: 0.7158 - val_loss: 0.5747 - val_accuracy: 0.7990\n",
            "Epoch 9/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.7622 - accuracy: 0.7256 - val_loss: 0.5632 - val_accuracy: 0.8036\n",
            "Epoch 10/60\n",
            "375/375 [==============================] - 11s 28ms/step - loss: 0.7324 - accuracy: 0.7347 - val_loss: 0.5543 - val_accuracy: 0.8088\n",
            "Epoch 11/60\n",
            "375/375 [==============================] - 7s 20ms/step - loss: 0.7216 - accuracy: 0.7411 - val_loss: 0.5428 - val_accuracy: 0.8119\n",
            "Epoch 12/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.7060 - accuracy: 0.7485 - val_loss: 0.5288 - val_accuracy: 0.8177\n",
            "Epoch 13/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.6931 - accuracy: 0.7518 - val_loss: 0.5253 - val_accuracy: 0.8192\n",
            "Epoch 14/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.6828 - accuracy: 0.7571 - val_loss: 0.5162 - val_accuracy: 0.8204\n",
            "Epoch 15/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.6728 - accuracy: 0.7595 - val_loss: 0.5095 - val_accuracy: 0.8257\n",
            "Epoch 16/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.6654 - accuracy: 0.7650 - val_loss: 0.5083 - val_accuracy: 0.8242\n",
            "Epoch 17/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.6488 - accuracy: 0.7703 - val_loss: 0.4917 - val_accuracy: 0.8289\n",
            "Epoch 18/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.6452 - accuracy: 0.7692 - val_loss: 0.4917 - val_accuracy: 0.8303\n",
            "Epoch 19/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.6334 - accuracy: 0.7752 - val_loss: 0.4848 - val_accuracy: 0.8325\n",
            "Epoch 20/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.6252 - accuracy: 0.7781 - val_loss: 0.4807 - val_accuracy: 0.8328\n",
            "Epoch 21/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.6163 - accuracy: 0.7818 - val_loss: 0.4842 - val_accuracy: 0.8328\n",
            "Epoch 22/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.6085 - accuracy: 0.7848 - val_loss: 0.4734 - val_accuracy: 0.8363\n",
            "Epoch 23/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.6115 - accuracy: 0.7854 - val_loss: 0.4700 - val_accuracy: 0.8383\n",
            "Epoch 24/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.6026 - accuracy: 0.7861 - val_loss: 0.4645 - val_accuracy: 0.8392\n",
            "Epoch 25/60\n",
            "375/375 [==============================] - 8s 20ms/step - loss: 0.5956 - accuracy: 0.7905 - val_loss: 0.4633 - val_accuracy: 0.8388\n",
            "Epoch 26/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5937 - accuracy: 0.7909 - val_loss: 0.4622 - val_accuracy: 0.8386\n",
            "Epoch 27/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5852 - accuracy: 0.7948 - val_loss: 0.4574 - val_accuracy: 0.8395\n",
            "Epoch 28/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.5798 - accuracy: 0.7965 - val_loss: 0.4522 - val_accuracy: 0.8401\n",
            "Epoch 29/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.5804 - accuracy: 0.7952 - val_loss: 0.4504 - val_accuracy: 0.8449\n",
            "Epoch 30/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.5737 - accuracy: 0.7978 - val_loss: 0.4463 - val_accuracy: 0.8452\n",
            "Epoch 31/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.5715 - accuracy: 0.7998 - val_loss: 0.4447 - val_accuracy: 0.8454\n",
            "Epoch 32/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5660 - accuracy: 0.8019 - val_loss: 0.4473 - val_accuracy: 0.8428\n",
            "Epoch 33/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5646 - accuracy: 0.8038 - val_loss: 0.4414 - val_accuracy: 0.8475\n",
            "Epoch 34/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5619 - accuracy: 0.8025 - val_loss: 0.4381 - val_accuracy: 0.8458\n",
            "Epoch 35/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5520 - accuracy: 0.8063 - val_loss: 0.4380 - val_accuracy: 0.8472\n",
            "Epoch 36/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5504 - accuracy: 0.8082 - val_loss: 0.4336 - val_accuracy: 0.8488\n",
            "Epoch 37/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5479 - accuracy: 0.8093 - val_loss: 0.4323 - val_accuracy: 0.8462\n",
            "Epoch 38/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5448 - accuracy: 0.8087 - val_loss: 0.4293 - val_accuracy: 0.8491\n",
            "Epoch 39/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5433 - accuracy: 0.8101 - val_loss: 0.4322 - val_accuracy: 0.8493\n",
            "Epoch 40/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5428 - accuracy: 0.8098 - val_loss: 0.4327 - val_accuracy: 0.8491\n",
            "Epoch 41/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5400 - accuracy: 0.8125 - val_loss: 0.4280 - val_accuracy: 0.8503\n",
            "Epoch 42/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5374 - accuracy: 0.8122 - val_loss: 0.4248 - val_accuracy: 0.8512\n",
            "Epoch 43/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5331 - accuracy: 0.8137 - val_loss: 0.4240 - val_accuracy: 0.8510\n",
            "Epoch 44/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.5306 - accuracy: 0.8147 - val_loss: 0.4234 - val_accuracy: 0.8513\n",
            "Epoch 45/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5207 - accuracy: 0.8170 - val_loss: 0.4150 - val_accuracy: 0.8525\n",
            "Epoch 46/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5199 - accuracy: 0.8186 - val_loss: 0.4169 - val_accuracy: 0.8545\n",
            "Epoch 47/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5199 - accuracy: 0.8187 - val_loss: 0.4174 - val_accuracy: 0.8524\n",
            "Epoch 48/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5158 - accuracy: 0.8198 - val_loss: 0.4111 - val_accuracy: 0.8517\n",
            "Epoch 49/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5195 - accuracy: 0.8202 - val_loss: 0.4141 - val_accuracy: 0.8555\n",
            "Epoch 50/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5135 - accuracy: 0.8207 - val_loss: 0.4129 - val_accuracy: 0.8516\n",
            "Epoch 51/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5127 - accuracy: 0.8209 - val_loss: 0.4110 - val_accuracy: 0.8540\n",
            "Epoch 52/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.5167 - accuracy: 0.8198 - val_loss: 0.4122 - val_accuracy: 0.8546\n",
            "Epoch 53/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5092 - accuracy: 0.8202 - val_loss: 0.4125 - val_accuracy: 0.8522\n",
            "Epoch 54/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.5074 - accuracy: 0.8213 - val_loss: 0.4113 - val_accuracy: 0.8529\n",
            "Epoch 55/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5088 - accuracy: 0.8221 - val_loss: 0.4067 - val_accuracy: 0.8547\n",
            "Epoch 56/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5037 - accuracy: 0.8221 - val_loss: 0.4103 - val_accuracy: 0.8558\n",
            "Epoch 57/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5080 - accuracy: 0.8223 - val_loss: 0.4034 - val_accuracy: 0.8569\n",
            "Epoch 58/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5038 - accuracy: 0.8248 - val_loss: 0.4039 - val_accuracy: 0.8568\n",
            "Epoch 59/60\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.4962 - accuracy: 0.8263 - val_loss: 0.4031 - val_accuracy: 0.8583\n",
            "Epoch 60/60\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.5019 - accuracy: 0.8247 - val_loss: 0.4009 - val_accuracy: 0.8597\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4223 - accuracy: 0.8511\n",
            "0.8511000275611877\n",
            "Accuracy: 85.11%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os, random\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "os.path.expanduser = lambda path: './'\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 60\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# for reproducibility\n",
        "import random, os\n",
        "os.environ['PYTHONHASHSEED']='0'\n",
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)\n",
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
        "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
        "from tensorflow.python.keras import backend as K\n",
        "K.set_session(sess)\n",
        "\n",
        "kernel_initializer='glorot_uniform'\n",
        "activation_function = 'relu'\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "    model.add(Dropout(0.8))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.8))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='sgd',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
        "print(metrics[1])\n",
        "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 분석\n",
        "\n",
        "## 1. 정확도 결과 정리 \n",
        "\n",
        "일단, 위의 실행 결과를 정리하면 아래와 같다.\n",
        "\n",
        "```\n",
        "Fashion MNIST : 87.32%\n",
        "Dropout rate 0.2 : 87.58%\n",
        "Dropout rate 0.5 : 86.98% \n",
        "Dropout rate 0.8 : 84.82% \n",
        "Dropout rate 0.2 + Batch Normalization : 88.67%\n",
        "Dropout rate 0.5 + Batch Normalization : 88.27%\n",
        "Dropout rate 0.8 + Batch Normalization : 85.11%\n",
        "```\n",
        "\n",
        "## 2. Dropout rate\n",
        "\n",
        "위의 결과를 보면 알 수 있듯이, Dropout rate가 0.2인 경우가 명시하지 않은 Fashion MNIST보다 정확도가 높다.\n",
        "\n",
        "하지만, dropout rate가 높아짐에 따라 정확도가 감소하여 dropout을 하지 않은 Fashion MNIST보다 작아지는 경향을 보인다.\n",
        "\n",
        "\n",
        "일단, dropout을 하는 이유는 무엇일까? \n",
        "\n",
        "간단하게 정리하면, overfitting을 방지해줄 수 있기 때문이다.\n",
        "\n",
        "overfitting을 어떻게 방지할까? \n",
        "- Dropout rate를 설정해주면, Neural Network에서의 Node간의 관계를 임의로 끊게 된다.\n",
        "- 그렇게 되면, Model capacity가 작아지는 효과를 얻게 되고 더 적은 파라미터로 모델에 대한 예측을 해야하기 때문에 overfitting을 어느정도 방지할 수 있게 되는 것이다.\n",
        "\n",
        "하지만 dropout rate를 너무 높게 잡으면, 너무 적은 양의 파라미터를 통해 모델을 예측을 해야되게 때문에 정확도가 떨어질 수 있다는 단점이 존재한다.\n",
        "\n",
        "그렇기에 0.5, 0.8으로 dropout rate가 높아졌을 때, 정확도가 낮아지는 양상을 보여준 것이다.\n",
        "\n",
        "그럼 dropout rate가 어느 정도쯤의 값이면 좋을까? \n",
        "확률적으로 접근해보면, 베르누이 분포에서 엔트로피를 가장 크게 할 수 있는 0.5가 가장 무난하게 사용할 수 있는 dropout rate임을 추측할 수 있다.\n",
        "\n",
        "\n",
        "## 3. Batch Normalization\n",
        "\n",
        "Batch Normalization은 학습을 할 때, 각 데이터를 배치별로 나누고 배치 데이터 별로 다양한 분포를 가지더라도 각 배치별로 평균과 분산을 이용해 정규화를 하는 과정이다.\n",
        "\n",
        "이러한 과정에서 미니 배치 ( 위에서 언급한 데이터별로 나눈 배치 ) 마다 평균과 분산을 계산하기 떄문에, 트레이닝 데이터 셋에 어느정도 noise를 발생시켜 overfitting을 방지하는 효과를 줄 수 있다.\n",
        "\n",
        "보통 dropout과 같이 사용하는 경우가 많고, 이번 프로젝트에서도 dropout과 함께 사용하였다.\n",
        "\n",
        "그래서 결과적으로 dropout만 사용했을 때와 dropout과 batch normalization을 함께 사용했을 때를 비교해보면 batch normalization이 overfitting을 방지해주어 정확도가 dropout만을 사용했을 때보다 높게 나오는 것을 알 수 있다.\n"
      ],
      "metadata": {
        "id": "WTQA9nwTjpdc"
      }
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "02_Fashion_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}